# Roadmap Detalhado: Modular Dashboard

Este roadmap detalha as fases, 칠picos e tarefas espec칤ficas para o desenvolvimento do projeto, com foco na implementa칞칚o da nova arquitetura de processamento de documentos. As tarefas s칚o numeradas em ordem de prioridade de execu칞칚o.

---

## Fase 1: Funda칞칚o e MVP (Conclu칤do 九덢잺)

_Esta fase representa o estado atual do projeto, com a arquitetura modular e funcionalidades b치sicas j치 implementadas._

#### Tarefas Conclu칤das:

* **Estrutura do Backend:** Implementada com FastAPI, garantindo alta performance e documenta칞칚o autom치tica de APIs.
* **Estrutura do Frontend:** Desenvolvida com React, TypeScript e Vite, para um ambiente de desenvolvimento moderno e r치pido.
* **Containeriza칞칚o:** Aplica칞칚o totalmente containerizada com Docker e Docker Compose, garantindo consist칡ncia entre ambientes.
* **Sistema de Modularidade:** Implementado no backend e frontend, permitindo a adi칞칚o de novas funcionalidades de forma desacoplada.
* **M칩dulo de Autentica칞칚o:** M칩dulo central (`core_module`) com autentica칞칚o via JWT para proteger os endpoints.
* **Banco de Dados:** Configurado com PostgreSQL e Alembic para gerenciamento de migra칞칫es do schema.
* **M칩dulos de Exemplo:** Criados m칩dulos iniciais (`gerador_quesitos`, `ai_test`, `info`) para validar a arquitetura.
* **Documenta칞칚o Inicial:** Criada a documenta칞칚o base sobre a arquitetura, estrutura de pastas e fluxo de trabalho.

---

## Fase 2: Infraestrutura de Processamento de Documentos (Foco Atual 游꿢)

**칄pico: Construir a Pipeline de Extra칞칚o de Texto como um Microservi칞o.**

_Objetivo: Criar a funda칞칚o de backend necess치ria para o processamento de PDFs de forma isolada e escal치vel. Ao final desta fase, teremos um servi칞o `worker` funcional e a API principal pronta para delegar tarefas a ele._

#### Tarefas Priorizadas:

1.  **Definir e Implementar o Schema do Banco de Dados:**
    * **Descri칞칚o:** Criar a migra칞칚o do Alembic no `backend` principal para adicionar a nova tabela.
    * **Tabela:** `pdf_processed_chunks`.
    * **Colunas:** `id` (PK), `file_hash` (VARCHAR(64), Indexed), `chunk_text` (TEXT), `page_number` (INTEGER), `created_at` (TIMESTAMPTZ).
    * **Entreg치vel:** Um novo arquivo de migra칞칚o do Alembic no diret칩rio `backend/alembic/versions`.

2.  **Configurar o Ambiente com `docker-compose.yml`:**
    * **Descri칞칚o:** Adicionar a defini칞칚o do novo `pdf_processor_service` ao arquivo `docker-compose.yml`.
    * **Especifica칞칫es:**
        * Nome do servi칞o: `pdf_processor`.
        * Deve construir a partir de um `Dockerfile` localizado em `./pdf_processor_service/`.
        * Deve compartilhar a rede (`app-network`) e o arquivo de ambiente (`.env`) com o `backend` principal.
        * Deve ter uma depend칡ncia expl칤cita do servi칞o `db` (`depends_on`).
    * **Entreg치vel:** Arquivo `docker-compose.yml` atualizado.

3.  **Criar a Estrutura Base do Microservi칞o:**
    * **Descri칞칚o:** Criar a estrutura de pastas e arquivos para o novo servi칞o.
    * **Estrutura:**
        ```
        /pdf_processor_service
        |-- /app
        |   |-- main.py
        |   |-- processing.py
        |   |-- database.py
        |-- Dockerfile
        |-- requirements.txt
        ```
    * **Entreg치vel:** A estrutura de pastas e arquivos b치sicos, incluindo um `Dockerfile` funcional e um `requirements.txt` com as depend칡ncias iniciais (`fastapi`, `uvicorn`, `pypdf`, `sqlalchemy`, `psycopg2-binary`).

4.  **Implementar a L칩gica de Extra칞칚o e Armazenamento no Microservi칞o:**
    * **Descri칞칚o:** Codificar a fun칞칚o principal no `processing.py` que recebe o conte칰do de um arquivo.
    * **Passos:**
        1.  Calcular o hash SHA-256 do arquivo.
        2.  Conectar-se ao PostgreSQL e verificar se o `file_hash` j치 existe. Se sim, retornar imediatamente.
        3.  Se n칚o existir, usar `PyPDFLoader` para extrair o texto.
        4.  Iterar sobre os "chunks" ou p치ginas e inseri-los na tabela `pdf_processed_chunks`.
    * **Entreg치vel:** C칩digo Python funcional no `pdf_processor_service`.

5.  **Criar o Endpoint de Processamento no Microservi칞o:**
    * **Descri칞칚o:** No `main.py` do `pdf_processor_service`, criar um endpoint (ex: `POST /process-pdf`) que recebe um `UploadFile`, chama a l칩gica de processamento e retorna um JSON com o `file_hash` e uma mensagem de status.
    * **Entreg치vel:** Endpoint FastAPI test치vel no microservi칞o.

6.  **Criar o Endpoint de Delega칞칚o na API Principal:**
    * **Descri칞칚o:** No `backend` principal, criar um novo endpoint (ex: `POST /api/v1/documents/upload-and-process`) que atua como um proxy.
    * **Passos:**
        1.  Recebe o `UploadFile` do cliente.
        2.  Usa `httpx` para repassar o arquivo para o endpoint do `pdf_processor_service`.
        3.  Aguarda a resposta e a retorna ao cliente.
    * **Entreg치vel:** Novo endpoint na API principal que orquestra a chamada para o microservi칞o.

---

## Fase 3: M칩dulo Piloto Aut칪nomo e Integra칞칚o (Pr칩ximos Passos 游)

**칄pico: Refatorar o `gerador_quesitos` para Usar a Nova Arquitetura.**

_Objetivo: Transformar o primeiro m칩dulo para que ele consuma a nova pipeline de processamento, servindo como um modelo para todos os futuros m칩dulos de IA._

#### Tarefas Priorizadas:

7.  **Refatorar o Frontend do M칩dulo `gerador_quesitos`:**
    * **Descri칞칚o:** Modificar o componente React (`GeradorQuesitos.tsx`).
    * **Passos:**
        1.  Adicionar um componente de UI para upload de arquivo (`<input type="file">`).
        2.  Implementar a l칩gica no frontend para chamar o novo endpoint de delega칞칚o (`/api/v1/documents/upload-and-process`).
        3.  Armazenar o `file_hash` retornado no estado do componente.
    * **Entreg치vel:** Interface do m칩dulo `gerador_quesitos` com capacidade de upload.

8.  **Refatorar o Backend do M칩dulo `gerador_quesitos`:**
    * **Descri칞칚o:** Modificar o endpoint existente do m칩dulo.
    * **Passos:**
        1.  O endpoint n칚o receber치 mais o arquivo, mas sim o `file_hash` e a pergunta do usu치rio.
        2.  A l칩gica interna buscar치 os `chunk_text` da tabela `pdf_processed_chunks` usando o `file_hash`.
        3.  Com os textos recuperados, a l칩gica existente do LangChain ser치 executada para vetorizar o texto, fazer a busca e gerar a resposta.
    * **Entreg치vel:** Endpoint do `gerador_quesitos` atualizado e funcional com a nova arquitetura.

---

## Fase 4: Expans칚o, Refinamento e Governan칞a (Vis칚o Futura 游댨)

**칄pico: Amadurecer a Plataforma e Expandir Funcionalidades.**

_Objetivo: Com a arquitetura principal definida e validada, o foco muda para a constru칞칚o de novas funcionalidades, melhoria da experi칡ncia do usu치rio e garantia da qualidade e seguran칞a do sistema._

#### Tarefas (Sem ordem de prioridade definida):

* **Desenvolver Novo M칩dulo: Analisador de Documentos (RAG):**
    * Criar um novo m칩dulo aut칪nomo que permite ao usu치rio "conversar" com um documento enviado, implementando o fluxo completo validado na Fase 3.

* **Implementar Controle de Acesso (RBAC):**
    * Associar permiss칫es a perfis de usu치rio (`Admin`, `User`).
    * Proteger m칩dulos e endpoints com base no perfil do usu치rio logado.

* **Melhorar a Experi칡ncia do Frontend:**
    * Implementar um seletor de tema (claro/escuro).
    * Preparar a estrutura para internacionaliza칞칚o (i18n).

* **Estabelecer CI/CD:**
    * Criar um pipeline no GitHub Actions para rodar testes e, futuramente, automatizar o deploy.

* **Implementar Logging e Monitoramento:**
    * Configurar um sistema de logging estruturado para todos os servi칞os.
    * Avaliar e implementar uma ferramenta de Application Performance Monitoring (APM).
